{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TensorFlow Input Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to use tf.data API framework in order to create a pipeine. Using PipeLine framework it is possible to conduct multiple functionalities the same time in our data(scaling, resizing etc.). For example : \n",
    "\n",
    "tf_dataset = tf.data.Dataset.list_files('images/*').map(process_img).filter(filter_func).map(lambda x: x/255)\n",
    "where : \n",
    "\n",
    "- list_files : load images \n",
    "- map(process_img) : conver image content to numpy array. Extract lable from folder \n",
    "- filter(filter_func) : Filter Blurred images \n",
    "- map(lambda x: x/255) : Scaling\n",
    "\n",
    "So, in fact we implemented all this preprocessing in one line. The next step would be to train the model : model.fit(tf_dataset)\n",
    "\n",
    "Benefits : \n",
    "\n",
    "            1) Handle huge datasets by streaming them from disk using batching\n",
    "            2) Apply tranformations to make dataset ready for model training\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the the first part I am building a simple input pipeline for my dogs-cats data.\n",
    "On the second part I will Optimize the TensorFlow pipeline : prefetch & cache "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **First Part**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from tensorflow.keras import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download the images from : https://www.kaggle.com/datasets/samuelcortinhas/cats-and-dogs-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the images \n",
    "images_ds = tf.data.Dataset.list_files('images/*/*', shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'images\\\\cats\\\\cat_345.jpg'\n",
      "b'images\\\\cats\\\\cat_152.jpg'\n",
      "b'images\\\\cats\\\\cat_103.jpg'\n",
      "b'images\\\\cats\\\\cat_240.jpg'\n",
      "b'images\\\\cats\\\\cat_109.jpg'\n",
      "b'images\\\\cats\\\\cat_16.jpg'\n",
      "b'images\\\\cats\\\\cat_263.jpg'\n",
      "b'images\\\\cats\\\\cat_180.jpg'\n",
      "b'images\\\\cats\\\\cat_223.jpg'\n",
      "b'images\\\\cats\\\\cat_224.jpg'\n",
      "b'images\\\\cats\\\\cat_361.jpg'\n",
      "b'images\\\\cats\\\\cat_246.jpg'\n",
      "b'images\\\\cats\\\\cat_281.jpg'\n"
     ]
    }
   ],
   "source": [
    "images_ds = images_ds.shuffle(200) # Shuffle the images\n",
    "\n",
    "for file in images_ds.take(13):\n",
    "    print(file.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train - test without using scikit-learn lib\n",
    "class_names = [\"cats\", \"dogs\"]\n",
    "image_count = len(images_ds)\n",
    "\n",
    "train_size = int(image_count * 0.8)\n",
    "train_ds = images_ds.take(train_size)\n",
    "test_ds = images_ds.skip(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for label extraction\n",
    "def get_label(file_path):\n",
    "    import os \n",
    "    return tf.strings.split(file_path,os.path.sep)[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def process_image(file_path):\n",
    "    label = get_label(file_path)\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_jpeg(img) # We need to decode the image\n",
    "    img = tf.image.resize(img, [128, 128]) # Resize the image\n",
    "    \n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'images\\\\cats\\\\cat_276.jpg'\n",
      "b'images\\\\cats\\\\cat_395.jpg'\n",
      "b'images\\\\cats\\\\cat_271.jpg'\n",
      "b'images\\\\cats\\\\cat_35.jpg'\n",
      "Image :  tf.Tensor(\n",
      "[[[29.    33.    32.   ]\n",
      "  [29.    33.    32.   ]\n",
      "  [29.    33.    32.   ]\n",
      "  ...\n",
      "  [31.875 47.875 11.875]\n",
      "  [31.875 47.75  12.125]\n",
      "  [29.875 44.875 14.875]]\n",
      "\n",
      " [[29.    33.    32.   ]\n",
      "  [29.    33.    32.   ]\n",
      "  [29.    33.    32.   ]\n",
      "  ...\n",
      "  [33.5   49.5   12.5  ]\n",
      "  [33.5   49.5   12.5  ]\n",
      "  [31.5   46.5   14.5  ]]\n",
      "\n",
      " [[29.    33.    32.   ]\n",
      "  [29.    33.    32.   ]\n",
      "  [29.    33.    32.   ]\n",
      "  ...\n",
      "  [35.    51.    12.   ]\n",
      "  [34.    50.    11.   ]\n",
      "  [30.75  46.75  10.75 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[32.    32.    32.   ]\n",
      "  [32.    32.    32.   ]\n",
      "  [33.    34.    29.   ]\n",
      "  ...\n",
      "  [29.    33.    32.   ]\n",
      "  [31.    33.    30.   ]\n",
      "  [35.25  34.    29.   ]]\n",
      "\n",
      " [[32.    32.    32.   ]\n",
      "  [32.    32.    32.   ]\n",
      "  [33.    34.    29.   ]\n",
      "  ...\n",
      "  [29.    33.    32.   ]\n",
      "  [30.5   32.    27.   ]\n",
      "  [43.75  34.25  29.5  ]]\n",
      "\n",
      " [[32.    32.    32.   ]\n",
      "  [32.    32.    32.   ]\n",
      "  [33.    34.    29.   ]\n",
      "  ...\n",
      "  [29.    33.    32.   ]\n",
      "  [33.    33.    27.5  ]\n",
      "  [53.75  37.375 32.5  ]]], shape=(128, 128, 3), dtype=float32)\n",
      "Label: tf.Tensor(b'cats', shape=(), dtype=string)\n",
      "Image :  tf.Tensor(\n",
      "[[[1.64000000e+02 1.66000000e+02 1.53000000e+02]\n",
      "  [1.67240921e+02 1.69240921e+02 1.56240921e+02]\n",
      "  [1.60446655e+02 1.62446655e+02 1.49446655e+02]\n",
      "  ...\n",
      "  [1.05024246e+02 1.04024246e+02 9.90242462e+01]\n",
      "  [1.03666809e+02 1.02666809e+02 9.76668091e+01]\n",
      "  [1.07195312e+02 1.07195312e+02 9.91953125e+01]]\n",
      "\n",
      " [[1.64850296e+02 1.66850296e+02 1.53850296e+02]\n",
      "  [1.67499893e+02 1.69499893e+02 1.56499893e+02]\n",
      "  [1.73828537e+02 1.75828537e+02 1.62828537e+02]\n",
      "  ...\n",
      "  [1.13292969e+02 1.12292969e+02 1.07292969e+02]\n",
      "  [1.04913956e+02 1.03913956e+02 9.89139557e+01]\n",
      "  [1.08753906e+02 1.08753906e+02 1.00753906e+02]]\n",
      "\n",
      " [[1.71094559e+02 1.73094559e+02 1.60094559e+02]\n",
      "  [1.65741241e+02 1.67741241e+02 1.54741241e+02]\n",
      "  [1.80929688e+02 1.82929688e+02 1.69929688e+02]\n",
      "  ...\n",
      "  [1.12714706e+02 1.11714706e+02 1.06714706e+02]\n",
      "  [1.05598480e+02 1.04598480e+02 9.95984802e+01]\n",
      "  [9.85602112e+01 9.85602112e+01 9.05602112e+01]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[3.41453400e+01 1.52641449e+01 5.70474243e+00]\n",
      "  [5.27041931e+01 3.00728607e+01 1.68706818e+01]\n",
      "  [5.51280823e+01 2.61280823e+01 8.85478210e+00]\n",
      "  ...\n",
      "  [1.59548248e+02 1.60548248e+02 1.64048523e+02]\n",
      "  [1.70129440e+02 1.69715378e+02 1.75060608e+02]\n",
      "  [1.57253632e+02 1.59372437e+02 1.64372437e+02]]\n",
      "\n",
      " [[3.55168915e+01 1.74478455e+01 7.65498352e+00]\n",
      "  [3.08436432e+01 8.84364319e+00 8.58306885e-02]\n",
      "  [6.76724091e+01 3.93037415e+01 2.38511505e+01]\n",
      "  ...\n",
      "  [1.46626724e+02 1.47626724e+02 1.51626724e+02]\n",
      "  [1.54570633e+02 1.54156570e+02 1.59156570e+02]\n",
      "  [1.25786636e+02 1.28786636e+02 1.33786636e+02]]\n",
      "\n",
      " [[2.32929688e+01 4.29296875e+00 0.00000000e+00]\n",
      "  [3.58005676e+01 1.38005676e+01 5.24197388e+00]\n",
      "  [6.40961761e+01 3.55844574e+01 2.15844574e+01]\n",
      "  ...\n",
      "  [1.24078537e+02 1.25078537e+02 1.29078537e+02]\n",
      "  [1.64884079e+02 1.64470016e+02 1.69470016e+02]\n",
      "  [1.33154877e+02 1.36154877e+02 1.41154877e+02]]], shape=(128, 128, 3), dtype=float32)\n",
      "Label: tf.Tensor(b'cats', shape=(), dtype=string)\n",
      "Image :  tf.Tensor(\n",
      "[[[236.     245.     250.    ]\n",
      "  [236.     245.     250.    ]\n",
      "  [236.     245.     250.    ]\n",
      "  ...\n",
      "  [248.     252.     253.    ]\n",
      "  [248.     252.     253.    ]\n",
      "  [249.     253.     254.    ]]\n",
      "\n",
      " [[236.     245.     250.    ]\n",
      "  [236.     245.     250.    ]\n",
      "  [236.     245.     250.    ]\n",
      "  ...\n",
      "  [248.     252.     253.    ]\n",
      "  [248.     252.     253.    ]\n",
      "  [249.     253.     254.    ]]\n",
      "\n",
      " [[236.     245.     250.    ]\n",
      "  [236.     245.     250.    ]\n",
      "  [236.     245.     250.    ]\n",
      "  ...\n",
      "  [248.     252.     253.    ]\n",
      "  [248.     252.     253.    ]\n",
      "  [249.     253.     254.    ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[236.     245.     250.    ]\n",
      "  [236.     245.     250.    ]\n",
      "  [236.     245.     250.    ]\n",
      "  ...\n",
      "  [246.     251.     255.    ]\n",
      "  [246.     251.     255.    ]\n",
      "  [246.9961 251.9961 255.    ]]\n",
      "\n",
      " [[236.     245.     250.    ]\n",
      "  [236.     245.     250.    ]\n",
      "  [236.     245.     250.    ]\n",
      "  ...\n",
      "  [246.     251.     255.    ]\n",
      "  [246.     251.     255.    ]\n",
      "  [246.     251.     255.    ]]\n",
      "\n",
      " [[236.     245.     250.    ]\n",
      "  [236.     245.     250.    ]\n",
      "  [236.     245.     250.    ]\n",
      "  ...\n",
      "  [246.     251.     255.    ]\n",
      "  [246.     251.     255.    ]\n",
      "  [246.     251.     255.    ]]], shape=(128, 128, 3), dtype=float32)\n",
      "Label: tf.Tensor(b'cats', shape=(), dtype=string)\n",
      "Image :  tf.Tensor(\n",
      "[[[207.6836  212.6836  216.6836 ]\n",
      "  [207.98438 212.98438 216.98438]\n",
      "  [221.10564 226.10564 230.10564]\n",
      "  ...\n",
      "  [246.      251.      255.     ]\n",
      "  [246.      251.      255.     ]\n",
      "  [246.      251.      255.     ]]\n",
      "\n",
      " [[231.74219 236.74219 240.74219]\n",
      "  [230.2003  235.2003  239.2003 ]\n",
      "  [237.02444 242.02444 246.02444]\n",
      "  ...\n",
      "  [246.      251.      255.     ]\n",
      "  [246.      251.      255.     ]\n",
      "  [246.      251.      255.     ]]\n",
      "\n",
      " [[243.96875 248.96875 252.96875]\n",
      "  [241.71535 246.71535 250.71535]\n",
      "  [242.0494  247.0494  251.0494 ]\n",
      "  ...\n",
      "  [246.      251.      255.     ]\n",
      "  [246.      251.      255.     ]\n",
      "  [246.      251.      255.     ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[216.78516 197.6211  180.45703]\n",
      "  [220.72656 201.72656 184.72656]\n",
      "  [225.10547 208.21094 192.3164 ]\n",
      "  ...\n",
      "  [218.2461  211.2461  203.2461 ]\n",
      "  [220.17528 213.17528 205.17528]\n",
      "  [221.59392 214.59392 206.59392]]\n",
      "\n",
      " [[218.6211  197.6211  178.6211 ]\n",
      "  [220.72656 201.72656 184.72656]\n",
      "  [225.55469 207.76172 192.3164 ]\n",
      "  ...\n",
      "  [221.85106 214.85106 206.85106]\n",
      "  [223.03516 216.03516 208.03516]\n",
      "  [224.89844 217.89844 209.89844]]\n",
      "\n",
      " [[218.6211  197.6211  178.6211 ]\n",
      "  [222.35938 201.72656 183.09375]\n",
      "  [226.10547 207.29704 190.7697 ]\n",
      "  ...\n",
      "  [222.07812 215.07812 207.07812]\n",
      "  [223.32031 216.32031 208.32031]\n",
      "  [225.1836  218.1836  210.1836 ]]], shape=(128, 128, 3), dtype=float32)\n",
      "Label: tf.Tensor(b'cats', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# Extract the labels\n",
    "for t in train_ds.take(4):\n",
    "    print(t.numpy())\n",
    "\n",
    "train_ds = train_ds.map(process_image)\n",
    "for img, label in train_ds.take(4):\n",
    "    print(\"Image : \" ,img)\n",
    "    print(\"Label:\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data Function\n",
    "def scale(image, label):\n",
    "    return image/255, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****Image:  [1. 1. 1.]\n",
      "****Label:  b'cats'\n",
      "****Image:  [0.9098039  0.94509804 0.972549  ]\n",
      "****Label:  b'cats'\n",
      "****Image:  [0.66926646 0.59867823 0.34769782]\n",
      "****Label:  b'cats'\n",
      "****Image:  [0.00392157 0.00392157 0.00392157]\n",
      "****Label:  b'cats'\n",
      "****Image:  [0.98579186 0.98971343 0.99755657]\n",
      "****Label:  b'cats'\n"
     ]
    }
   ],
   "source": [
    "# Scale data\n",
    "train_ds = train_ds.map(scale)\n",
    "for image, label in train_ds.take(5):\n",
    "    print(\"****Image: \", image.numpy()[0][0])\n",
    "    print(\"****Label: \", label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Second Part**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize TensorFlow Pipeline Performance\n",
    "\n",
    "Using prefetch function of the pipeline we can train our model simutanelsy in CPU and GPU. \n",
    "A simple structure for example would be : \n",
    "\n",
    "- tf.data.Dataset.list_files('images/*').map(process_img).filter(filter_func).map(lambda x: x/255).prefetch(AUTOTUNE)\n",
    "\n",
    "where : \n",
    "\n",
    "        - list_files : Load images from images folder\n",
    "        - map : Convert image content to numpy array. Extract label from folder\n",
    "        - filter : Filter blurred images \n",
    "        - map(lambda x: x/255) : Scaling\n",
    "        - prefetch(AUTOTUNE) : prefetching\n",
    "\n",
    "Before we train the model it would be a good practice to remove the redundant functionalities. We don't need to open the file each time and scale each time. In order to avoid that we can use \"tf.data.Dataset.cache()\". Using  cache we are saving time by not doing redundant things like opening the file on each epoch.\n",
    "\n",
    "Following the above structure we can then fit the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure the difference between using and not using prefetch \n",
    "\n",
    "class FileDataset(tf.data.Dataset):\n",
    "    \n",
    "    def read_files_in_batches(num_samples):\n",
    "        # open file\n",
    "        time.sleep(0.03) # Just mimic the delay on opening the file\n",
    "        for sample_idx in range(num_samples):\n",
    "            time.sleep(0.015)\n",
    "            \n",
    "            yield (sample_idx,) # yield is a generator here\n",
    "            \n",
    "    def __new__(cls, num_samples = 3):\n",
    "        \n",
    "        return tf.data.Dataset.from_generator(\n",
    "            cls.read_files_in_batches,\n",
    "            output_signature = tf.TensorSpec(shape = (1,), dtype = tf.int64),\n",
    "            args = (num_samples,)\n",
    "        )\n",
    "\n",
    "def benchmark(dataset, num_epochs = 2):\n",
    "    for epoch_num in range(num_epochs):\n",
    "        for sample in dataset:\n",
    "            time.sleep(0.01) # Sleep time counting for GPU calculations \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319 ms ± 39.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "benchmark(FileDataset())            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303 ms ± 18.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "benchmark(FileDataset().prefetch(tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the above 2 implementations we can see that regarding time, the **prefetch** method has reduced the computational time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.range(15)\n",
    "\n",
    "\n",
    "dataset = dataset.map(lambda x: x**2)\n",
    "\n",
    "for d in dataset:\n",
    "    print(d.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144, 169, 196]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use cache now : \n",
    "\n",
    "dataset  = dataset.cache()\n",
    "list(dataset.as_numpy_iterator())\n",
    "# Using cache the model it is not using the lambda function (map) again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapped_function(s):\n",
    "    tf.py_function(lambda : time.sleep(0.03), [], ())\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.27 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "benchmark(FileDataset().map(mapped_function), 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "benchmark(FileDataset().map(mapped_function).cache(), 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using **cache** we can see that the need time is less than half of the implementation without cache.\n",
    "The reason for this behaviour is that we use the mapped function only for the first epochs. For the rest of the epochs the code uses the same data as the first epochs. This means that for higher num of epochs we are goiing to have larger differences in time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
